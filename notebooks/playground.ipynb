{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "import predictability_utils as pu\n",
    "from predictability_utils.utils import helpers, io\n",
    "\n",
    "root_data = '../../data/pyrina'\n",
    "\n",
    "# air pressure at mean sea level (North Atlantic & EU) ANOMALIES\n",
    "msl_naeu_anomalies, _ = io.data_load('msl', 'NA-EU', 'anomalies', root_data)\n",
    "\n",
    "# sea surface temperatures (North Atlantic & EU) ANOMALIES\n",
    "sst_naeu_anomalies, sst_naeu_anomalies_mask = io.data_load('sst', 'NA-EU', 'anomalies', root_data)\n",
    "\n",
    "# Volumetric soil water layer 1 (EU) ANOMALIES\n",
    "swvl1_eu_anomalies, _ = io.data_load('swvl1', 'EU', 'anomalies', root_data)\n",
    "\n",
    "# Temperature at 2m (EU) ANOMALIES\n",
    "t2m_eu_anomalies, _ = io.data_load('t2m', 'EU', 'anomalies', root_data)\n",
    "\n",
    "# sea surface temperatures (TNA) ANOMALIES\n",
    "sst_tna_anomalies, sst_tna_anomalies_mask = io.data_load('sst', 'TNA', 'anomalies', root_data)\n",
    "\n",
    "# training data time stamps and map shape\n",
    "nc_fn = root_data + \"/t2m_ERA20c_monthly_1900-2010.EU.mv.nc\"\n",
    "ts = Dataset(nc_fn, 'r').variables['time'].__array__().data\n",
    "t2m_eu = Dataset(nc_fn, 'r').variables['t2m'].__array__().data\n",
    "map_shape = t2m_eu.shape[1:]\n",
    "\n",
    "train_months, test_months = [2,3,4], [5,6,7]\n",
    "y_train = 51\n",
    "\n",
    "tmp = helpers.split_train_data(ts, y_train, train_months, test_months)\n",
    "idx_source_train, idx_target_train, idx_source_test, idx_target_test = tmp\n",
    "\n",
    "# let's not miss a year\n",
    "assert np.prod(idx_source_train.shape) + np.prod(idx_source_test.shape) == len(ts)/12 * len(train_months)\n",
    "assert np.prod(idx_target_train.shape) + np.prod(idx_target_test.shape) == len(ts)/12 * len(test_months)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(t2m_eu[::12,:,:].mean(axis=0))\n",
    "plt.title('avg t2m map for EU')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(sst_tna_anomalies_mask[0,:,:])\n",
    "plt.title('TNA mask (SSTs))')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(sst_naeu_anomalies_mask[0,:,:])\n",
    "plt.title('NA EU mask (SSTs)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latents = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recreate CCA analysis\n",
    "- Canonical correlation analysis to identify subspaces $U$, $V$ in source space $X$ and target space $Y$, respectively, such that $(UX)_i$ and $(VY)_i$ are maximally correlated.\n",
    "- in a second step, establish a (linear) mapping from $VY \\approx Q UX$ to predict $VY$ from $UX$.\n",
    "- predict new $Y$ from $Y \\approx V^\\dagger Q UX$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictability_utils.methods.cca_method import CCA_method\n",
    "from predictability_utils.utils import viz\n",
    "\n",
    "# predict T2ms in Summer from soil moisture levels in Spring (1900 - 1950)\n",
    "X = swvl1_eu_anomalies.reshape(len(ts), -1)[idx_source_train,:].mean(axis=0)\n",
    "Y = t2m_eu_anomalies.reshape(len(ts), -1)[idx_target_train,:].mean(axis=0)\n",
    "\n",
    "# fit CCA-based model\n",
    "ccam = CCA_method(n_latents=n_latents)\n",
    "ccam.fit(X,Y)\n",
    "\n",
    "# predict T2ms for test data (1951 - 2010)\n",
    "X_f = swvl1_eu_anomalies.reshape(len(ts), -1)[idx_source_test,:].mean(axis=0)\n",
    "out_pred = ccam.predict(X_f)\n",
    "\n",
    "# evaluate prediction performance\n",
    "out_true = t2m_eu_anomalies.reshape(len(ts), -1)[idx_target_test,:].mean(axis=0)\n",
    "anomaly_corrs = helpers.compute_anomaly_corrs(out_true, out_pred)\n",
    "\n",
    "# visualize anomaly correlations\n",
    "viz.visualize_anomaly_corrs(anomaly_corrs.reshape(*map_shape))\n",
    "\n",
    "# visualize example predictions for selected years\n",
    "viz.visualize_example_preds(out_true, out_pred, map_shape, y_train, years=[0,15,30,45])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple low-rank linear prediction (pixel MSEs) \n",
    "\n",
    "- set up simple model $Y = W X$ with $W = U V$\n",
    "- low-rank: if $Y \\in \\mathbb{R}^N, X \\in \\mathbb{R}^M$, then $W \\in \\mathbb{R}^{N \\times M}$, but $U \\in \\mathbb{R}^{N \\times k}, V \\in \\mathbb{R}^{k \\times M}$ with $k << M,N$ !\n",
    "- low-rank structure saves us parameters: $M N$ parameters in $W$, but only $N k + k M$ in $U$ and $V$, helps prevent overfitting on low samples size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from predictability_utils.methods.lrlin_method import LR_lin_method\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# predict T2ms in Summer from soil moisture levels in Spring\n",
    "X = torch.tensor(swvl1_eu_anomalies.reshape(len(ts), -1)[idx_source_train,:].mean(axis=0))\n",
    "Y = torch.tensor(t2m_eu_anomalies.reshape(len(ts), -1)[idx_target_train,:].mean(axis=0))\n",
    "    \n",
    "# fit CCA-based model\n",
    "lrlm = LR_lin_method(n_latents=n_latents)\n",
    "loss_vals = lrlm.fit(X,Y, n_epochs=3000)\n",
    "\n",
    "plt.semilogx(loss_vals[100:])\n",
    "plt.title('loss curve')\n",
    "plt.show()\n",
    "\n",
    "# predict T2ms for test data (1951 - 2010)\n",
    "X_f = swvl1_eu_anomalies.reshape(len(ts), -1)[idx_source_test,:].mean(axis=0)\n",
    "out_pred = lrlm.predict(X_f)\n",
    "\n",
    "# evaluate prediction performance\n",
    "out_true = t2m_eu_anomalies.reshape(len(ts), -1)[idx_target_test,:].mean(axis=0)\n",
    "anomaly_corrs = helpers.compute_anomaly_corrs(out_true, out_pred)\n",
    "\n",
    "# visualize anomaly correlations\n",
    "viz.visualize_anomaly_corrs(anomaly_corrs.reshape(*map_shape))\n",
    "\n",
    "# visualize example predictions for selected years\n",
    "viz.visualize_example_preds(out_true, out_pred, map_shape, y_train, years=[0,15,30,45])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
